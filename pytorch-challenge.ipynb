{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bi_zifPQbM_o"
   },
   "source": [
    "**Scratchpad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2025,
     "status": "ok",
     "timestamp": 1546263213082,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "mnQDNUWzbQoP",
    "outputId": "1fa26a3a-6808-4531-a198-a894f33f1c27"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7_L6q8WZoCB"
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6DdapmeZQkb"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCFe0A9ccP70"
   },
   "source": [
    "**Get Data from Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71651,
     "status": "ok",
     "timestamp": 1546276315573,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "LLsZHb0lcPba",
    "outputId": "1c7cecfb-f9de-40a4-c4cc-2719e9c41b90"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131622
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14876,
     "status": "ok",
     "timestamp": 1546276363034,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "ZWK9GVYkcwuG",
    "outputId": "27a368c0-19c0-4755-f4ff-bd22f8ecb6f7"
   },
   "outputs": [],
   "source": [
    "!cp /content/gdrive/'My Drive'/pytorch_challenge/flower_data.zip /content\n",
    "!unzip /content/flower_data.zip\n",
    "# !ls /content/flower_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9X8lsTduaBqa"
   },
   "source": [
    "**Downloads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38253,
     "status": "ok",
     "timestamp": 1546276186508,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "_MybAUMNaElt",
    "outputId": "015c4991-82fb-4232-ed4f-61c7f0187af5"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "#accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "accelerator = 'cu80'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6624,
     "status": "ok",
     "timestamp": 1546276217550,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "MiAq7LCv1_6u",
    "outputId": "c322a07c-753f-4870-99ec-9803defe587e"
   },
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir -I pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQdRaz4-aUIz"
   },
   "source": [
    "**Constants/Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDAzIMGpaawJ"
   },
   "outputs": [],
   "source": [
    "TRN_DATA_DIR = \"/content/flower_data/train\"\n",
    "VAL_DATA_DIR = \"/content/flower_data/valid\"\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n",
    "LOAD_MODEL = True\n",
    "\n",
    "# 'inception', 'resnet18', 'resnet152',\n",
    "# 'densenet121', 'densenet201'\n",
    "MODEL_TO_USE = 'densenet201'\n",
    "INPUT_SIZE = { 'inception': (299, 299, 3),\n",
    "               'resnet': (224, 224, 3),\n",
    "               'densenet': (224, 224, 3) }\n",
    "OUTPUT_SIZE = 102\n",
    "MODEL_DIR = 'checkpoints'\n",
    "MODEL_FN = 'densenet201_20e.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10523,
     "status": "ok",
     "timestamp": 1546276415772,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "nco-pOkMg6Tk",
    "outputId": "4482f368-b545-4616-e575-cfb43d0c2cad"
   },
   "outputs": [],
   "source": [
    "!mkdir 'checkpoints'\n",
    "!cp /content/gdrive/'My Drive'/pytorch_challenge/checkpoints/densenet201_20e.pth checkpoints/\n",
    "!ls checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkaO0KU-aOTX"
   },
   "source": [
    "**Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqmmeWpqaQI_"
   },
   "outputs": [],
   "source": [
    "def get_data_gen(input_size):\n",
    "    '''Initialize data loader\n",
    "    '''\n",
    "    side_len = min(input_size[:2])\n",
    "    # for training\n",
    "    train_transforms = transforms.Compose([transforms.Resize(side_len),\n",
    "                                           transforms.RandomCrop(side_len),\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.RandomRotation(30),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "    train_data = datasets.ImageFolder(TRN_DATA_DIR, transform=train_transforms)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                                              batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # for validation\n",
    "    valid_transforms = transforms.Compose([transforms.Resize(side_len),\n",
    "                                           transforms.RandomCrop(side_len),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "    valid_data = datasets.ImageFolder(VAL_DATA_DIR, transform=valid_transforms)\n",
    "    validloader = torch.utils.data.DataLoader(valid_data,\n",
    "                                              batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    return trainloader, validloader\n",
    "\n",
    "def get_modified_squeezenet():\n",
    "    '''Return squeezenet with frozen layers\n",
    "    '''\n",
    "    model = models.squeezenet1_1(pretrained=True)\n",
    "\n",
    "    # Squeezenet contains two Sequential\n",
    "    seqs = list(model.children())\n",
    "    # first Sequential is for feature extraction\n",
    "    for param in seqs[0].parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # second Sequential is for classification\n",
    "    # we replace only the output size, which is the\n",
    "    # output channel of the Conv2d\n",
    "    for child in seqs[1]:\n",
    "        if child.__class__.__name__ == \"Conv2d\":\n",
    "            # replace Conv2d\n",
    "            print(\"replace\")\n",
    "\n",
    "    return model \n",
    "\n",
    "def get_modified_inception():\n",
    "    '''Return inception3 with frozen layers\n",
    "    '''\n",
    "    model = models.inception_v3(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # replace fc\n",
    "    classifier = nn.Sequential(\n",
    "        nn.Linear(2048, 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.6),\n",
    "        nn.Linear(1024, OUTPUT_SIZE)\n",
    "    )\n",
    "\n",
    "    model.fc = classifier\n",
    "    # work around to remove aux from output\n",
    "    model.aux_logits = False\n",
    "\n",
    "    return model \n",
    "  \n",
    "def get_modified_resnet(size):\n",
    "    '''Return resnet with frozen layers\n",
    "    '''\n",
    "    if size == 18:\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        in_features = 512\n",
    "    elif size == 152:\n",
    "        model = models.resnet152(pretrained=True)\n",
    "        in_features = 2048\n",
    "    else:\n",
    "        raise Exception(\"Unsupported model type!\")\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # replace fc\n",
    "    classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(512, OUTPUT_SIZE)\n",
    "        )\n",
    "\n",
    "    model.fc = classifier\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_modified_densenet(size, mode='freeze_dense'):\n",
    "    '''Return densenet with frozen layers\n",
    "    '''\n",
    "    if size == 121:\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        in_features = 1024\n",
    "    elif size == 201:\n",
    "        model = models.densenet201(pretrained=True)\n",
    "        in_features = 1920\n",
    "    else:\n",
    "        raise Exception(\"Unsupported model type!\")\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # replace classifier\n",
    "    classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(512, OUTPUT_SIZE)\n",
    "        )\n",
    "\n",
    "    model.classifier = classifier\n",
    "    \n",
    "    if mode == 'freeze_linear':\n",
    "            \n",
    "        for param in model.features.denseblock4.parameters():\n",
    "            param.requires_grad = True                   \n",
    "            \n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fLC6fYxTawe4"
   },
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2oR_AUC5C7l"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(model, validloader, loss_f, train_on_gpu):\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        corrects = 0\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        for images, labels in tqdm(validloader):\n",
    "            # move data to gpu\n",
    "            if(train_on_gpu):\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "            logits = model.forward(images)\n",
    "            val_loss += loss_f(logits, labels)\n",
    "\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            preds = probs.cpu().numpy().argmax(axis=1)\n",
    "            preds = torch.from_numpy(preds)\n",
    "            if(train_on_gpu):\n",
    "                preds = preds.cuda()\n",
    "            corrects += torch.sum(preds == labels).type(torch.FloatTensor)\n",
    "            total += len(labels)\n",
    "\n",
    "    accuracy = float(corrects / total)\n",
    "    print(\"Validation Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lP3Cs7Hta2q-"
   },
   "outputs": [],
   "source": [
    "def train(model_name, model):\n",
    "    '''Perform model training\n",
    "    '''\n",
    "    # prepare data generator\n",
    "    input_size = INPUT_SIZE[model_name]\n",
    "    trainloader, validloader = get_data_gen(input_size)\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        ckpt = torch.load(os.path.join(MODEL_DIR, MODEL_FN))\n",
    "        model.load_state_dict(ckpt)\n",
    "        #print(\"Loaded %s.\" % (os.path.join(MODEL_DIR, MODEL_FN)))\n",
    "\n",
    "    # First checking if GPU is available\n",
    "    train_on_gpu=torch.cuda.is_available()\n",
    "    if(train_on_gpu):\n",
    "        print('Training on GPU.')\n",
    "        model.cuda()\n",
    "    else:\n",
    "        print('No GPU available, training on CPU.')\n",
    "\n",
    "    # prepare loss and optimizer functions\n",
    "    loss_f = nn.CrossEntropyLoss()\n",
    "    #optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                          lr=0.01, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                     factor=0.1, patience=1,\n",
    "                                                     verbose=True)    \n",
    "    \n",
    "    if LOAD_MODEL:\n",
    "       check_accuracy(model, validloader, loss_f, train_on_gpu)\n",
    "    \n",
    "    # perform training\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = np.inf\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "        for images, labels in tqdm(trainloader):\n",
    "            # move data to gpu\n",
    "            if(train_on_gpu):\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "            # Clear the gradients, do this because gradients are accumulated\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass, then backward pass, then update weights\n",
    "            logits = model.forward(images)\n",
    "            loss = loss_f(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                total = 0\n",
    "                corrects = 0\n",
    "                val_loss = 0\n",
    "                model.eval()\n",
    "                for images, labels in tqdm(validloader):\n",
    "                    # move data to gpu\n",
    "                    if(train_on_gpu):\n",
    "                        images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "                    logits = model.forward(images)\n",
    "                    val_loss += loss_f(logits, labels)\n",
    "\n",
    "                    probs = F.softmax(logits, dim=1)\n",
    "                    preds = probs.cpu().numpy().argmax(axis=1)\n",
    "                    preds = torch.from_numpy(preds)\n",
    "                    if(train_on_gpu):\n",
    "                        preds = preds.cuda()\n",
    "                    corrects += torch.sum(preds == labels).type(torch.FloatTensor)\n",
    "                    total += len(labels)\n",
    "\n",
    "            accuracy = float(corrects / total)\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            val_losses.append(val_loss/len(validloader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, NUM_EPOCHS),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "                  \"Validation Loss: {:.3f}.. \".format(val_loss/len(validloader)),\n",
    "                  \"Validation Accuracy: {:.3f}\".format(accuracy))\n",
    "\n",
    "            print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                # save model\n",
    "                torch.save(model.state_dict(), os.path.join(MODEL_DIR, MODEL_FN))\n",
    "                print(\"Saved to %s.\" % os.path.join(MODEL_DIR, MODEL_FN))\n",
    "                best_val_loss = val_loss\n",
    "            \n",
    "            # adjust learning rate based on validation loss\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "    # graph training and validation loss\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(val_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZn815Bwa8RK"
   },
   "source": [
    "**Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1900
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5930544,
     "status": "ok",
     "timestamp": 1546282547377,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "o2Mh-OmNa7c8",
    "outputId": "57518a34-9a4b-48a8-f87a-4cd5d79bd420"
   },
   "outputs": [],
   "source": [
    "MODEL_TO_USE = 'densenet201'\n",
    "if MODEL_TO_USE == 'squeezenet':\n",
    "    model = get_modified_squeezenet()\n",
    "elif MODEL_TO_USE == 'inception':\n",
    "    model = get_modified_inception()\n",
    "elif 'resnet' in MODEL_TO_USE:\n",
    "    sz = int(MODEL_TO_USE.strip('resnet'))\n",
    "    model = get_modified_resnet(sz)\n",
    "    MODEL_TO_USE = 'resnet'\n",
    "elif 'densenet' in MODEL_TO_USE:\n",
    "    sz = int(MODEL_TO_USE.strip('densenet'))\n",
    "    model = get_modified_densenet(sz, mode='freeze_linear')\n",
    "    MODEL_TO_USE = 'densenet'\n",
    "else:\n",
    "    print(\"Unsupported model type!\")\n",
    "\n",
    "train(MODEL_TO_USE, model)\n",
    "!cp checkpoints/densenet201_20e.pth /content/gdrive/'My Drive'/pytorch_challenge/checkpoints"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch-challenge.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
